# [ACL2022]Knowledge-enhenced_NLG_Survey

> by WangYC
>
> @NWPU chang'an Jun.1st-9th
>
> åŸæ–‡è¿æ¥ï¼šhttp://arxiv.org/abs/2010.04389
>
> <img src="Knowledge-enhenced_NLG_Survey.assets/image-20220608105554293.png" alt="image-20220608105554293" style="zoom:50%;" />

[toc]

## 1. Introduction

NLGæ˜¯NLPé¢†åŸŸçš„ä¸€ä¸ªé‡è¦è¯¾é¢˜ï¼Œå…¶ä»»åŠ¡æ˜¯ä»å¤šç§å½¢å¼çš„è¾“å…¥ä¸­äº§ç”Ÿå¯ç†è§£çš„äººç±»è¯­è¨€ã€‚

å…¶ä¸­text-to-textæ˜¯NLGæœ€é‡è¦çš„åº”ç”¨ä¹‹ä¸€ï¼Œç®€ç§°text-generation,ã€‚

text-generationä»¥textä¸ºè¾“å…¥ï¼Œä»ä¸­äº§ç”Ÿä¸­é—´è¯­ä¹‰è¡¨è¾¾ï¼Œæœ€åç”Ÿæˆç›®æ ‡textã€‚

text-generationçš„å…·ä½“çš„ä»»åŠ¡åœºæ™¯åŒ…æ‹¬æœºå™¨ç¿»è¯‘ã€æ€»ç»“ã€é—®ç­”ä»¥åŠå¯¹è¯ç³»ç»Ÿç­‰ã€‚

éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯å¤å…´ï¼Œè®¸å¤šæ·±åº¦æ¨¡å‹åœ¨ç†è§£è¯­ä¹‰ä¸Šè¡¨ç°ä¸å‡¡ã€‚

ä¸€ä¸ªåŸºç¡€çš„text-generationä»»åŠ¡æ˜¯2014å¹´æå‡ºçš„seq2seqã€‚ä»é‚£ä»¥åï¼Œæ¶Œç°å‡ºäº†å¾ˆå¤štext-generationæ¨¡å‹ï¼Œæœ€ä¸»è¦çš„åŒ…æ‹¬ï¼š

* RNN
* CNN
* Transformer

ç„¶è€Œä¸Šè¿°å·¥ä½œçŸ¥è¯†ä»æœ‰é™çš„è¾“å…¥å¯¹è¯­è¨€å’Œè¯­ä¹‰è¿›è¡Œç†è§£ï¼Œè¿™ç›¸æ¯”äºäººç±»åœ¨æ—¥å¸¸å¯¹è¯æˆ–é—®ç­”æ—¶é€šè¿‡å¤§é‡çŸ¥è¯†æ¥è¾…åŠ©æœ‰ç€å¾ˆå¤§å·®è·ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦æƒ³åŠæ³•ä»è¾“å…¥ä»¥å¤–çš„çŸ¥è¯†å¾—åˆ°å¸®åŠ©ã€‚

> This research direction of **incorporating knowledge into** **text generation** is named as knowledge-enhanced text generation

### 1.1 knowledge-enhanced text generation

knowledge source å¯ä»¥åˆ†ä¸ºå†…éƒ¨å’Œå¤–éƒ¨ä¸¤ç±»ã€‚

> since knowledge can be obtained from different sources, we first divide existing knowledge enhanced text generation work into two categories**: internal knowledge enhanced and external knowledge enhanced** text generation. The division of internal and external knowledge is widely adopted by **management science**, which can be analogous with knowledge enhanced text generation
>

![image-20220607102355400](Knowledge-enhenced_NLG_Survey.assets/image-20220607102355400.png)

å†…éƒ¨çŸ¥è¯†åŒ…æ‹¬topicã€keywordsç­‰ï¼Œä»è¾“å…¥ä¸­å¯ä»¥æå–åˆ°çš„çŸ¥è¯†ã€‚

å¤–éƒ¨çŸ¥è¯†æŒ‡ä»å¤–éƒ¨æºè·å–åˆ°çš„çŸ¥è¯†ä¿¡æ¯ï¼ŒåŒ…æ‹¬knowledge base, external knowledge graphä»¥åŠgrounded textç­‰ç­‰ã€‚

ç›®å‰å·²ç»æœ‰è®¸å¤šknowledge- enhancedçš„modelåœ¨text generationä»»åŠ¡ä¸Šè¡¨ç°éå‡¡ã€‚

### 1.2 the survey itself

![image-20220607110505534](Knowledge-enhenced_NLG_Survey.assets/image-20220607110505534.png)

> To the best of our knowledge, this is the first survey that presents a comprehensive review of knowledge-enhanced text generation.

â€”â€”æœ¬æ–‡æ˜¯ç¬¬ä¸€ç¯‡å…³äºknowledge enhanced text generationçš„ç»¼è¿°

### 1.3 challenges

1. ä»ä¼—å¤šknowledge sourceä¸­è·å–æœ‰ç”¨çš„ã€ç›¸å…³çš„çŸ¥è¯†

   section 2-4

2. å¦‚ä½•é«˜æ•ˆåœ°ç†è§£å’Œå……åˆ†åˆ©ç”¨è·å–åˆ°çš„çŸ¥è¯†æ¥è¿›è¡Œè¯­ä¹‰ç†è§£

   å„sectionä¸­çš„ M1, M2, and etc

   

æ€»ç»“æ¥è¯´ï¼Œè¿™ç¯‡ç»¼è¿°è®¨è®ºäº†è‡ª2016å¹´ä»¥æ¥çš„è¶…è¿‡80ç¯‡æ–‡ç« æç‚¼å‡ºçš„7ä¸ªä¸»æµåº”ç”¨ã€‚

Section2 ï¼šåŸºç¡€çš„NLGæ¨¡å‹å’Œæ€»ä½“çš„å°†knowledgeåº”ç”¨åˆ°text-generationçš„æ–¹æ³•

Section3 ï¼šå†…éƒ¨æ–¹æ³•å’Œåº”ç”¨ï¼ˆtopic, keyword, linguistic features and internal graph structuresï¼‰

Section4 ï¼šå¤–éƒ¨æ–¹æ³•å’Œåº”ç”¨ï¼ˆ knowledge bases, knowledge graphs, and grounded textï¼‰

Section5 ï¼šNLGbenchmarks

Section6 ï¼šæœªæ¥å±•æœ›ä»¥åŠæ€»ç»“

## 2. General method of Integrating knowledge into NLG

### 2.1 basic text generation model

æ•´ä½“æ¡†æ¶ï¼šencoder-decoder framework
$$
P(Y|X) = P(y_1, \cdots, y_m | x_1, \cdots, x_n) = \prod_{t = 1}^mp(y_t|X, y_1, \cdots, y_{t - 1})
$$
å°†yå½“ä½œæ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼Œå› æ­¤å¯ä»¥è½¬åŒ–æˆä¸ºæ¦‚ç‡ç›¸ä¹˜çš„å½¢å¼ã€‚

encoderï¼š
$$
(h_1, h_2, \cdots, h_n) = ENCODER(e(x_1), e(x_2), \cdots, e(x_n))
$$
decoder & readoutï¼š
$$
s_t = DECODER(s_{t - 1}, e(y_{t - 1})),
\\p(y_t|y_{t - 1}, y_{t - 2}, \cdots, y_1) = READOUT(s_t)
$$
ä¼˜åŒ–æ€è·¯&lossï¼šå°†ç”Ÿæˆä»»åŠ¡çœ‹ä½œæ˜¯ä¸€ä¸ªåºåˆ—çš„å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼Œå¯ä»¥é‡‡ç”¨negative log likelihood (NLL) lossï¼Œä¼˜åŒ–ç­–ç•¥maximum likelihood estimation (MLE)

### 2.2 knowledge-enhanced model architecture

ä¸€ä¸ªå°†knowledgeå¼•å…¥çš„æ€è·¯å°±æ˜¯è®¾è®¡ç‰¹å®šçš„èƒ½å¤Ÿåæ˜ ç‰¹å®šknowledgeçš„æ¨¡å‹æ¶æ„ã€‚

ç”±æ­¤å¼•å…¥ä¼—å¤šèƒ½å¤Ÿæå–å…¨å±€ä¿¡æ¯çš„ç½‘ç»œæ¶æ„ï¼š

#### 2.2.1 attention

åœ¨åšdecoderçš„æ—¶å€™ï¼Œä¸Šä¸‹æ–‡å‘é‡$c_t$è¢«å¼•å…¥ï¼š
$$
s_t = DECODER(s_{t - 1}, e(y_{t - 1}, c_t))
$$
**RNN seq2seq decoder:**
$$
c_t = \sum_{t = 1} ^n\alpha_{ti}h_i, where \  \alpha_{ti} = \frac{exp(\eta(s_{t - 1}, h_i))}{\sum_{k = 1}^nexp(\eta(s_{t  - 1}, h_k))}
$$
å…¶ä¸­çš„$\eta()$ä¸ºmlpæˆ–è€…å…¶ä»–çº¿æ€§å‡½æ•°ï¼Œç›®çš„æ˜¯ä¸ºäº†èƒ½å¤Ÿè®¡ç®—æ¢¯åº¦ã€‚

ä»¥å‰çš„å·¥ä½œåˆ—ä¸¾äº†æœ‰å…­ç§$\eta$çš„æ›¿æ¢å‡½æ•° ã€‚

**Transformer decoder:**
$$
S_t = TRANSFORMER-DECODER(S_{t - 1}, e(y_{t - 1}), H)
$$
**æ·»åŠ knowledgeçš„attentionæ–¹æ³•ï¼š**

ä¸€ä¸ªå¸¸ç”¨çš„æ€è·¯å°±æ˜¯åœ¨è¿™ä¸ª$c_t$ä¸Šä¸‹åŠŸå¤«ï¼Œå°†çŸ¥è¯†å‘é‡åŠ åˆ°è¿™ä¸ªä¸Šä¸‹æ–‡å‘é‡ä¸­ã€‚
$$
\widetilde{c_t} = c_t \oplus c_t^K
$$
å…¶ä¸­çš„$c_t^K$æ˜¯é€šè¿‡knowledge representationsä¸Šattentionå¾—åˆ°çš„ï¼Œä¾‹å¦‚åœ¨knowledge graphä¸­çš„topic vectors, node vectors

#### 2.2.2 copy and pointing

copyNet å’Œ Pointer-Generator(PG)ä»è¾“å…¥ä¸­æ‰¾å­é›†åºåˆ—å°†å…¶é‡æ–°ç»„ç»‡é¡ºåºæ”¾åœ¨è¾“å‡ºåºåˆ—çš„åˆé€‚ä½ç½®ã€‚

äºŒè€…æœ€ç»ˆè¾“å‡ºçš„å¯èƒ½æ€§åˆ†ä¸ºä¸¤ä¸ªæ¨¡å¼ï¼šgeneration-modeå’Œcopy-modeã€‚

äºŒè€…çš„åŒºåˆ«åœ¨äºå¦‚ä½•åŠ æƒä¸¤ä¸ªmodeï¼š

copyNet: $p(y_t) = p_g(y_t) + p_c(y_t)$

PG: $p(y_t) = p_m(g) \cdot p_g(y_t) + (1 - p_m(g)) \cdot p_c(y_t)$

ç›¸å½“äºæ„å»ºäº†ä¸€ä¸ªvocabularyï¼š
$$
V_{ext} = V_{global} \or V_{X} \or {unk}
$$
**å°†knowledgeå¼•å…¥ï¼š**

åŠ å…¥ä¸€ä¸ªæ–°çš„modeï¼Œknowledge mode: ä»knowledge baseä¸­æŒ‘é€‰åºåˆ—å¹¶åœ¨è¾“å‡ºä¸­æŒ‰é¡ºåºè¾“å‡ºã€‚

ç›¸å½“äºvocabularyæ‹“å±•ï¼š


$$
V_{ext} = V_{global} \or V_X \or V_{knowledge}
$$

#### 2.2.3 memory network

memory networkçš„æ€è·¯å°±æ˜¯è¿™ä¸ªåå­—æ‰€è¡¨ç¤ºçš„ï¼Œåˆ©ç”¨ç±»ä¼¼äºå†…å­˜çš„æœºåˆ¶ï¼Œå°†é•¿å¯¹è¯çš„è¯­å¢ƒä¿¡æ¯ç­‰ä¿å­˜èµ·æ¥ï¼Œéšååœ¨å¯¹è¾“å…¥æ±‚embeddingçš„æ—¶å€™å¾ªç¯éå†å†…å­˜çŸ©é˜µï¼Œæ±‚åŠ æƒå’Œä½œä¸ºåºåˆ—çš„embeddingçš„ä¸€éƒ¨åˆ†ã€‚åˆ©ç”¨è¾“å…¥çš„åºåˆ— $Â h_k$ä½œä¸ºç´¢å¼•æ¥è¿›è¡Œéå†ï¼Œæœ€åå°†$o^K$ä½œä¸ºembeddingé€åˆ°decoderä¸­ã€‚
$$
p_i^k = softmax((h_X^k)^T C_i^k)
\\ \ 
\\ \
\\o^k= \sum_ip_i^kC_i^{k+1}
\\ \ 
h_X^{k + 1} = h_X^k + o^k
$$
**å°†knowledegå¼•å…¥çš„æ–¹æ³•ï¼š**

åˆ©ç”¨knowledge base ä»¥åŠtopic

decoderåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½å¤ŸåŒæ­¥æ£€ç´¢memoryä¸­çš„ä¿¡æ¯

#### 2.2.4 graph network

è¿‘æœŸçš„GNNé‡‡ç”¨èšåˆé‚»å±…ä¿¡æ¯çš„æ–¹å¼æ¥è¡¨å¾èŠ‚ç‚¹ã€‚

åç»­ç« èŠ‚ä¼šå¯¹å›¾ç»“æ„åœ¨MLGä¸Šçš„åº”ç”¨è¿›è¡Œå…·ä½“ä»‹ç»ï¼š

knowledge graph (Section 4.2), dependency graph (Section 3.3.2-3.3.3), and open knowledge graph (OpenKG) (Section 3.4)

#### 2.2.5 pre-trained LMs

é¢„è®­ç»ƒlanguage modelç›®çš„æ˜¯åœ¨å¤§è§„æ¨¡æ— æ ‡ç­¾è¯­æ–™åº“ä¸Šè¿›è¡Œè‡ªç›‘ç£è®­ç»ƒã€‚

åœ¨å¤„ç†ä¸knowledgeç›¸å…³çš„ä»»åŠ¡çš„æ—¶å€™å‡ºç°ä¸¤ä¸ªå›°éš¾ï¼š

1. PLMså¾ˆéš¾æå–åˆ°å…³ç³»ä»¥åŠæ¦‚å¿µç­‰å¸¸è¯†ä¿¡æ¯ï¼›
2. ç”±äºé¢„è®­ç»ƒçš„æ—¶å€™æœ‰ç‰¹å®šçš„é¢†åŸŸï¼Œå› æ­¤åœ¨è·¨é¢†åŸŸçš„æƒ…æ™¯ä¸Šæ— æ³•æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚

è§£å†³æ–¹æ¡ˆï¼š

1. ä»å¤–éƒ¨knowledge sourceä¸­è®¡ç®—ç›¸å…³çŸ¥è¯†çš„è¡¨ç¤ºå¹¶å°†entityç›´æ¥è¡¨ç¤ºè¿›PLMä¸­ï¼ˆä¾‹å¦‚å°†è¿™äº›entityä½œä¸ºè¾…åŠ©è¾“å…¥ï¼‰

   ä½†æ˜¯è¿™ç§æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ä»å¤–éƒ¨sourceä¸­æå–è¡¨ç¤ºçš„è¿™ä¸ªè¿‡ç¨‹ä¸å†…éƒ¨ä¿¡æ¯çš„å¤„ç†è¿‡ç¨‹æ˜¯è§£å¶çš„ï¼Œæ„å‘³ç€ä»ä¸¤éƒ¨åˆ†è·å–åˆ°çš„ä¿¡æ¯ä¼šæœ‰æ˜æ˜¾çš„å·®å¼‚æˆ–ä¸è¿ç»­çš„é—®é¢˜ã€‚

2. ç›´æ¥é€šè¿‡åšknowledgeç›¸å…³çš„ä»»åŠ¡æ¥è¿›è¡Œé¢„è®­ç»ƒï¼Œä¾‹å¦‚CALMå°†knowledgeæ‰“åŒ…è¿›å‚æ•°ï¼Œå¹¶åŒæ—¶åšgenerative å’Œ contrastiveçš„NLGtasksã€‚

### 2.3 knowledge-enhanced learning & inference

é™¤äº†åœ¨æ¨¡å‹ç»“æ„ä¸Šåšè°ƒæ•´ä»¥å¤–ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒç­–ç•¥ä¸Šç€æ‰‹å°†knowledgeå¼•å…¥ã€‚ä¸€ä¸ªé€šç”¨çš„æ–¹æ³•å°±æ˜¯é€šè¿‡supervised knowledge learning

#### 2.3.1 learning with knowledge-related task

å¯ä»¥å°†ä»»åŠ¡æœ¬èº«è®¾è®¡æˆknowledgeç›¸å…³çš„ï¼Œå› æ­¤æ¨¡å‹å¯ä»¥å­¦åˆ°çŸ¥è¯†ç›¸å…³çš„ä¿¡æ¯ã€‚

##### knowledge as target

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220608110123178.png" alt="image-20220608110123178" style="zoom:50%;" />

ç›´æ¥å°†knowledgeä½œä¸ºç”Ÿæˆç›®æ ‡çš„ä¸€éƒ¨åˆ†ï¼Œä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç§æ€è·¯ï¼š

1. ä»inputä¸­æå–éƒ¨åˆ†knowledgeï¼Œä¸knowledgeçš„labelåšå¯¹æ¯”æ±‚ä¸€ä¸ªknowledge lossï¼Œå†ç”¨inputæ­£å¸¸èµ°æ¨¡å‹å¾—å‡ºçš„outputä¸labelsåšä¸€ä¸ªgeneration lossï¼Œæœ€åè¿™ä¸¤ä¸ªlossåˆå¹¶ä½œä¸ºæ€»çš„lossã€‚
2. å¼±ç›‘ç£æ€æƒ³ï¼šç›´æ¥å°†knowledgeèå…¥åˆ°æ ‡å‡†è¾“å‡ºä¸­ï¼Œä½œä¸ºlabelçš„ä¸€éƒ¨åˆ†ã€‚

##### knowledge as condition

å°†knowledgeå½“ä½œæ˜¯ä¸€ç§æ¡ä»¶ï¼Œä¹Ÿå°±æ˜¯åœ¨ç›¸åŒçš„è¾“å…¥æƒ…å†µä¸‹ï¼Œæœ‰ä¸åŒç±»knowledgeçš„æ¡ä»¶ä¸‹ï¼Œè¾“å‡ºåº”è¯¥æœ‰ç›¸åº”çš„å˜åŒ–ã€‚
$$
p_\theta(Y|X, K)
$$
å®é™…æ“ä½œä¸Šå¸¸é‡‡ç”¨soft enforcing algorithmsä¾‹å¦‚ attention mechanismä»¥åŠcopy/pointing mechanism

è¿˜æœ‰ä¸€ç§å¾ˆé€šè¡Œçš„æ–¹æ³•æ˜¯åˆ©ç”¨**VAE**æ¥åšknowledgeæ¡ä»¶ä¸‹çš„text generating

#### 2.3.2 learning with knowledge constraints

å°†knowledgeä½œä¸ºä¸€ç§é™åˆ¶æ¡ä»¶ï¼Œæœ€ç»ˆçš„å­¦ä¹ ä»»åŠ¡ä¸ºä¼˜åŒ–é—®é¢˜ï¼š
$$
\max_{\theta,q}L(\theta) - KL(q(Y|X)||p_\theta(Y|X))+ \xi
\\ \ 
s.t. E_q[f(X, Y)] > \xi
$$

#### 2.3.3 inference with knowledge constraints

å¦‚æœä¸è°ƒæ•´æ¨¡å‹ç»“æ„çš„è¯ï¼Œå¾ˆéš¾åšåˆ°knowledge çš„å¼•å…¥æˆ–åˆ©ç”¨ç‰¹å®šdataè¿›è¡Œfine-tuneï¼Œä»è€Œæ§åˆ¶language generation

Plug and play language model PPLMæ¨¡å‹æå‡ºäº†åˆ©ç”¨knowledgeä½œä¸ºé™åˆ¶è¿›è¡Œæ¨ç†çš„æ–°æ–¹æ³•ã€‚

## 3. NLG enhanced by internal knowledge

### 3.1 by Topic

topicæŒ‡çš„æ˜¯ä¸€ä¸ªè¯­å¥åºåˆ—ä¸­æç‚¼å‡ºæ¥çš„ä¸­å¿ƒè¯é¢˜ã€‚

é€šè¿‡topicæ¥enhanceçš„NLGåº”ç”¨ï¼š

1. å¯¹è¯ç³»ç»Ÿ 2. æœºå™¨ç¿»è¯‘ 3. é‡Šä¹‰

é€šè¿‡topicæ¥è¿›è¡ŒNLGçš„æ€è·¯æœ‰ä»¥ä¸‹å‡ ç§ï¼š

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220608181430635.png" alt="image-20220608181430635" style="zoom:50%;" />

#### 3.1.1 leverage topic words from generative topic models

ç›´æ¥ä»inputä¸­é€šè¿‡generative topic modelæŠ½å–å‡ºtopic wordsã€‚

LDAæ˜¯generative topic modelä¸­çš„ä¸€ç§ï¼Œæ˜¯Latent Dirichlet allocationçš„ç¼©å†™ï¼Œå¯ä»¥åšä»æŒ‡å®šåºåˆ—ä¸­æç‚¼å‡ºtopic wordçš„å·¥ä½œã€‚

#### 3.1.2 jointly optimize generation model and CNN topic model

CNN topic modelé€šè¿‡å·ç§¯ä»¥åŠä¸‹é‡‡æ ·ç­‰æ‰‹æ®µæ¥ä»topicä¸­ç›´æ¥æå–topicçš„embeddingï¼Œè™½ç„¶è¡¨ç°å¾ˆå¥½ä½†æ˜¯ç¼ºä¹ç†è®ºè§£é‡Šå’Œé²æ£’æ€§ã€‚

#### 3.1.3 enhance NLG by neural topic models with variational inference

ä¹‹æ‰€ä»¥æŠŠneuralæ–¹æ³•å’ŒCNNåˆ†å¼€æ¥è°ˆæ˜¯å› ä¸ºCNNçš„åå‘ä¼ æ’­ä¸ä¼ ç»Ÿçš„neuralæ–¹æ³•æœ‰å¾ˆå¤§ä¸åŒï¼Œè¿™é‡Œè®²åˆ°çš„neuralæ–¹æ³•æŒ‡å¯ä»¥é«˜æ•ˆåˆ©ç”¨åå‘ä¼ æ’­è®­ç»ƒçš„æ¨¡å‹ã€‚

neuralæ–¹æ³•ç»¼åˆäº†ç¥ç»ç½‘ç»œä»¥åŠæ¦‚ç‡æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œå¯ä»¥æç‚¼æ›´åŠ æœ‰å±‚æ¬¡ã€æ›´è¿è´¯çš„topic

ä½†æ˜¯neuralæ–¹æ³•å…±æœ‰çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼Œtopicçš„åˆ’åˆ†è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªæ··åˆé«˜æ–¯åˆ†å¸ƒï¼Œå¯¼è‡´æ¨¡å‹å¯¹äºtopicä¹‹é—´çš„å…³ç³»ç‰¹å¾æ— æ³•å¾ˆå¥½çš„æç‚¼ï¼Ÿ

> topic distribution is assumed to be an isotropic Gaussian, which makes them incapable of modeling topic correlations

æ–‡ç« æ€»ç»“äº†ä¸€äº›topicæ¨¡å‹ï¼Œåˆ†åˆ«ç”¨äºå‡ ä¸ªä¸åŒçš„ä»»åŠ¡ä¸Šï¼Œæœ‰ç›¸åº”çš„è¡¨ç°æƒ…å†µï¼š

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220608192945266.png" alt="image-20220608192945266" style="zoom:50%;" />

### 3.2 by Keywords

keywordså¯ä»¥è§†ä½œä¸€ç§å¯¹äºè¾“å…¥çš„æ–‡ä»¶æˆ–è€…æ–‡æœ¬åºåˆ—çš„ä¸€ç§é«˜å‡ç»ƒåº¦çš„æ¦‚æ‹¬ï¼Œå¯¹äºæå–keywordæœ‰ä»¥ä¸‹åº”ç”¨åœºæ™¯ï¼š

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220608200006957.png" alt="image-20220608200006957" style="zoom:50%;" />

åˆ†æˆä»¥ä¸‹ä¸¤ç§å¤§çš„ä¸»æµæ–¹æ¡ˆï¼š

1. å…³é”®å­—èµ‹å€¼ï¼ˆä»å¤–éƒ¨æ‰¾åˆ°åˆé€‚çš„å…³é”®å­—ï¼‰
2. å…³é”®å­—æå–ï¼ˆä»è¾“å…¥ä¸­æ‰¾å…³é”®å­—ï¼‰

#### 3.2.1 Incorporate keyword assignment into text generation

##### 3.2.1.1 Adding assigned keyword into the decoder

ä»å¤–éƒ¨vocabularyä¸­æ‰¾åˆ°åˆé€‚çš„å…³é”®å­—ï¼Œæœ‰ä¸€ä¸ªå¾ˆç”ŸåŠ¨çš„ä¾‹å­ï¼š

> **For example,** a dialogue utterance â€œIf you had stopped him that day, things would have been different.â€ expresses sadness but it does not have the word â€œsad.â€

æœ‰ç‚¹ç±»ä¼¼äºä¸€ç§æƒ…æ„Ÿåˆ†ç±»å™¨ï¼Œæ˜¯ä¸€ç§åˆ†ç±»ä»»åŠ¡ã€‚

##### 3.2.1.2 Assigning keyword for generated sequence

ä¸Šé¢ä¸€ç§æ–¹æ³•çš„é—®é¢˜å°±æ˜¯æŸä¸€ä¸ªæƒ…æ„Ÿçš„åˆ†ç±»æ¦‚ç‡ä¼šè¿œå¤§äºå…¶ä»–æƒ…æ„Ÿï¼Œå¯¼è‡´å…¶ä»–çš„æƒ…æ„Ÿæ— æ³•ä½“ç°å‡ºæ¥ï¼Œæ¯”æ–¹è¯´å¥å­æ˜¯ä¸€ä¸ªæ‚²ä¸­å¸¦å–œçš„æƒ…æ„Ÿï¼Œä½†æ˜¯ç”±äºæ‚²ä¼¤çš„æˆåˆ†æ›´å¤§ï¼Œå› æ­¤æœ€ç»ˆçš„å…³é”®å­—å¯èƒ½ä¼šæ˜¯sadï¼Œå®Œå…¨è¡¨ç¤ºä¸å‡ºæ¥happyçš„æˆåˆ†ã€‚è¿˜æœ‰ä¸€ä¸ªé—®é¢˜å°±æ˜¯å…³é”®è¯ä¼šå¤§éƒ¨åˆ†éƒ½æ˜¯æƒ…æ„Ÿç±»è¯æ±‡ï¼Œæ²¡å…¶ä»–ä¸œè¥¿äº†ã€‚

è€Œè¿™ç§æ–¹æ³•æ˜¯åˆ©ç”¨æƒ…æ„Ÿæ¥æŒ‡å¯¼ç”Ÿæˆçš„æ–‡æœ¬ï¼Œæ¯”å¦‚æç‚¼å‡ºäº†ç‰¹å®šæƒ…æ„Ÿhappyï¼Œé‚£ä¹ˆå°±ä»è¡¨ç¤ºhappyçš„vocabularyä¸­æ‰¾å…³é”®å­—ã€‚

#### 3.2.2 Incorporate keyword extraction into text generation

å­—é¢æ„æ€ï¼Œç›´æ¥ä»è¾“å…¥çš„æ–‡ä»¶æˆ–è€…åºåˆ—ä¸­æ‰¾å…³é”®å­—ã€‚

ä¸€ç§å¸¸ç”¨çš„åšæ³•æ˜¯ç”¨multitaskçš„æ€æƒ³ï¼Œè®­ç»ƒkeyword extractorå’Œ generating summariesçš„å…±åŒæ¨¡å‹ï¼Œå› ä¸ºäºŒè€…çš„ç›®çš„ç±»ä¼¼ï¼Œå¯ä»¥ç›¸è¾…ç›¸æˆï¼Œå‚æ•°å…±äº«ã€‚



æ€»ç»“æ¥è¯´ï¼Œç”¨keywordæœ€å¥½æ˜¯åœ¨æ€»ç»“æç‚¼è¿™ç±»çš„ä»»åŠ¡ä¸­ï¼Œè€Œä¸æ˜¯åœ¨ç”Ÿæˆçš„ä»»åŠ¡ä¸­ï¼Œå› ä¸ºä¸€æ—¦æå–é”™è¯¯ï¼Œç”Ÿæˆæ¨¡å‹çš„åç»­ç”Ÿæˆç»“æœå…¨éƒ½è·‘åäº†ï¼Œå½±å“è¿‡å¤§äº†ã€‚

### 3.3 by Linguistic Features

è¯­è¨€ç‰¹å¾åŒ…æ‹¬è¯æ€§ã€è¯ä¹‰ã€ä¸å¥ä¹‹é—´çš„ä¾èµ–å…³ç³»ç­‰

#### 3.3.1 POS tags and NER tags

POSæŒ‡è¯æ€§ï¼Œæ·»åŠ è¯æ€§ä¿¡æ¯å¯ä»¥æé«˜æœºå™¨å¯¹äºè¯­å¥åºåˆ—çš„ç†è§£èƒ½åŠ›ï¼Œä¾‹å¦‚æ‰“è¯æ€§æ ‡ç­¾noun (N), verb (V), adjective (A).ã€‚

NERæŒ‡çš„æ˜¯Namedentity recognition (NER)ï¼Œå®ä½“æ ‡æ³¨ï¼Œä¾‹å¦‚person (P), location (L), organization (O)

å¸¸ç”¨å·¥å…·ï¼šCoreNLP

#### 3.3.2 Syntactic dependency graph

ç»“æ„ä¾èµ–å…³ç³»å›¾ï¼Œ

> For example, in the sentence â€œThe monkey eats a bananaâ€, â€œmonkeyâ€ is the subject of the predicate â€œeatsâ€, and â€œbananaâ€ is the object

å¤„ç†æ–¹æ³•æœ‰ä¸‰ç§æ€è·¯ï¼š

1. å°†graphçº¿æ€§åŒ–åé‡‡ç”¨åºåˆ—æ¨¡å‹å¤„ç†ã€‚
2. é‡‡ç”¨è·¯å¾„åŒ–æ€æƒ³ï¼Œé€šè¿‡å›¾æ±‚è·ç¦»ï¼Œå¦‚æœä¸¤ä¸ªè¯çš„è·ç¦»è¶Šè¿œï¼Œé‚£åœ¨æœ€ç»ˆè¡¨ç¤ºçš„æ—¶å€™æ‰€å çš„æƒé‡å°±è¶Šå°ã€‚
3. ç›´æ¥é‡‡ç”¨GNNæ¥å¤„ç†ä¾èµ–å…³ç³»

#### 3.3.3 Semantic dependency graph

åŒæ—¶é‡‡ç”¨åºåˆ—encoderä»¥åŠgraph encoderï¼Œå¯¹åºåˆ—çš„ä¿¡æ¯å’Œgraphè¡¨ç¤ºçš„è¯­ä¹‰ä¾èµ–ä¿¡æ¯è¿›è¡Œencodingï¼Œæœ€åå°†å›¾ä¿¡æ¯æ³¨å…¥åˆ°è¯­ä¹‰è¡¨ç¤ºä¸­ã€‚

### 3.4 by Open Knowledge Graphs

KGå¯ä»¥æŒ‰ç…§æ˜¯å¦å®Œå…¨æ ¹æ®è¾“å…¥çš„ä¿¡æ¯æ„å»ºæ¥åˆ†ä¸ºinternalKGä»¥åŠexternalKG

é€šè¿‡internalKGæ¥åŠ å¼ºNLGçš„æ–¹æ³•ï¼š

Step1:é¦–å…ˆè¦èƒ½ä»è¾“å…¥çš„ä¿¡æ¯ä¸­æ„å»ºä¸€ä¸ªinternalKGï¼šOpenIE

Step2:ä»KGä¸­æå–è¡¨ç¤ºå¹¶å°†å…¶ç”¨åœ¨ç”Ÿæˆæ¨¡å‹ä¸­ï¼šä¸€ç¯‡å·¥ä½œä¸­åˆ©ç”¨GATå­¦KGçš„ä¿¡æ¯ï¼Œç„¶åé€šè¿‡transformeræ¥è¿›è¡Œç¼–ç å’Œè§£ç 

## 4. NLG enhanced by external knowledge

### 4.1 by Knowledge Base

KBæ˜¯ä¸€ä¸ªä¸‰å…ƒç»„é›†åˆï¼Œæ¯ä¸ªä¸‰å…ƒç»„ä¸­æœ‰subject, pre, object å°†KBç”¨äºNLGä»»åŠ¡çš„æ–¹æ³•ä¸ºç»™å®šinputååœ¨KBä¸­æ£€ç´¢ç›¸å…³æ€§æœ€é«˜çš„å‡ ä¸ªæ¡ç›®è¿›è¡Œè¾…åŠ©ç”Ÿæˆã€‚

#### 4.1.1 Design Supervised Tasks around KB for Joint Optimization

å¸¸ç”¨çš„æ–¹æ³•ä¸ºå¤šä»»åŠ¡ç³»ç»Ÿï¼Œè¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸é—®é¢˜ç†è§£ä¸factæ£€ç´¢ç­‰ä»»åŠ¡ååŒè®­ç»ƒï¼Œç§°ä¸ºæ‰€è°“çš„â€œSupervised Tasksâ€

å…·ä½“å®ç°çš„å·¥ä½œå…¸å‹æœ‰KBCopyä»¥åŠCoreQA

å…¶ä¸­CoreQAçš„æ€è·¯æ˜¯åˆ©ç”¨æ£€ç´¢æ¨¡å‹ä»inputä¸­åšquestion understandingä»»åŠ¡ä»¥åŠfactæ£€ç´¢ä»»åŠ¡ï¼Œæ¥å¾—åˆ°KBä¸­ä¸inputç›¸å…³çš„å‡ ä¸ªfactï¼Œç„¶åå¯¹inputå’Œfactåšattentionï¼Œæ¥å¾—åˆ°æœ€ç»ˆçš„è¯­è¨€åºåˆ—ã€‚

å…¶ä¸­question understandingç»è¿‡ç¼–ç åå¾—åˆ°å¤§çš„å›ç­”ç»“æ„ï¼Œç»“æ„ä¸­å…·ä½“çš„ä¿¡æ¯é€šè¿‡factæ¥å¡«ç©ºã€‚

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609095555271.png" alt="image-20220609095555271" style="zoom:50%;" />

#### 4.1.2 Enhance Incorporation by Selecting KB or Facts in KB

ä¸Šè¿°æ–¹æ³•çš„é—®é¢˜åç»­æ–‡æœ¬çš„ç”Ÿæˆè¿‡äºä¾èµ–ä¹‹å‰ç”Ÿæˆçš„æ–‡æœ¬ä¿¡æ¯äº†ã€‚

äºæ˜¯æå‡ºäº†ä¸€ç§åˆ©ç”¨KLæ•£åº¦æ¥é€‰æ‹©æ­£ç¡®çš„factçš„æ–¹æ³•ã€‚

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609095811059.png" alt="image-20220609095811059" style="zoom:50%;" />

### 4.2 by Knowledge Graph

KGæ˜¯ä¸€ç§ç»“æ„åŒ–çš„çŸ¥è¯†è¡¨ç¤ºï¼Œç”±å®ä½“ã€å…³ç³»ä»¥åŠè¯­ä¹‰è§£é‡Šæ„æˆï¼Œä¸KBä¸åŒçš„æ˜¯KGä»¥Graphä¸ºç»“æ„åŸºç¡€ï¼Œèƒ½å¤Ÿè¡¨ç¤ºæ›´åŠ å¤æ‚çš„å®ä½“é—´çš„è¿æ¥å…³ç³»ã€‚

KGåœ¨NLGæ–¹é¢çš„åº”ç”¨ä¸»è¦æœ‰ï¼š

* Commonsense Reasoning
* Dialogue system
* Creative writing

KGå®šä¹‰ï¼š
$$
G = (U, \varepsilon, R)
$$
å…¶ä¸­Uæ˜¯å®ä½“ï¼Œ$\varepsilon$ æ˜¯è·¯å¾„ï¼Œ$\varepsilon \subseteq U \times R \times U$ , è¿™ä¸ªRå°±æ˜¯æŒ‡å®šçš„æ¨¡å¼ï¼ˆç»™å®šçš„æŸç§æˆ–æŸå‡ ç§å…³ç³»ï¼‰



è¯­å¥ç›¸å…³çš„KGå­å›¾çš„å®šä¹‰ï¼š
$$
G_{sub} = (U_{sub}, \varepsilon_{sub}, R)
$$
è¡¨ç¤ºKæ¡èŒƒå›´å†…çš„å­å›¾ã€‚

åˆ©ç”¨KGçš„æ–¹æ³•å¯ä»¥å¤§è‡´æ€»ç»“ä¸ºå››ç§ï¼š

1. Incorporate Knowledge Graph Embeddings into Language Generation
2. Transfer Knowledge into Language Model with Knowledge Triplet Information
3. Perform Reasoning over Knowledge Graph via Path Finding Strategies
4.  Improve the Graph Embeddings with Graph Neural Networks

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609160222305.png" alt="image-20220609160222305" style="zoom:50%;" />

#### 4.2.1 Incorporate Knowledge Graph Embeddings into Language Generation

KGEæ˜¯ä¸€é¡¹å¯¹KGçš„èŠ‚ç‚¹è¡¨ç¤ºçš„æ–¹æ³•ï¼Œå°†èŠ‚ç‚¹ä»¥åŠè¾¹è¿›è¡Œå‘é‡åŒ–è¡¨ç¤ºï¼Œä»¥åœ¨è¡¨å¾ç©ºé—´ä¸­ä½“ç°å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚

ä¾‹å¦‚ç»è¿‡TransEè¡¨ç¤ºçš„KGï¼Œè¡¨ç¤ºå‡ºçš„ç»“æœæ»¡è¶³å…³ç³»ï¼šè‹¥æœ‰èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»($u_i, \varepsilon, u_j$ ), åˆ™åœ¨è¡¨å¾ç©ºé—´ä¸­æœ‰$e_{u_i} + e_{\varepsilon} = e_{u_j}$

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609144122566.png" alt="image-20220609144122566" style="zoom:50%;" />

#### 4.2.2 Transfer Knowledge into Language Model with Knowledge Triplet Information

ç›´æ¥åˆ©ç”¨graph2seqæ¨¡å‹å°†KGä¸­çš„å®ä½“ä¹‹é—´çš„è¿æ¥å…³ç³»è½¬åŒ–æˆä¸ºè¯­è¨€åºåˆ—ï¼Œç»è¿‡é¢„è®­ç»ƒæ³¨å…¥åˆ°æ¨¡å‹å‚æ•°ä¸­ã€‚

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609144920178.png" alt="image-20220609144920178" style="zoom:50%;" />

#### 4.2.3 Perform Reasoning over Knowledge Graph via Path Finding Strategies

é€šè¿‡è·¯å¾„æŸ¥æ‰¾ç®—æ³•æ¥è¿›è¡Œæ¨ç†ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨KGçš„Graphç»“æ„ä¼˜åŠ¿ã€‚

åˆ†ä¸ºpath ranking baseçš„æ–¹æ³•ä»¥åŠå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼š

##### 4.2.3.1 Path routing and ranking

path ranking algorithm(PRA)åœ¨large-scaledçš„KGä¸Šè¡¨ç°ä¸å‡¡ï¼Œåˆ©ç”¨éšæœºæ¸¸èµ°ç®—æ³•ï¼Œæ·±åº¦ä¼˜å…ˆæœç´¢çš„æ€æƒ³ï¼Œæ‰¾åˆ°å¯èƒ½çš„å…³ç³»ï¼Œæœç´¢ç›®æ ‡å®ä½“ã€‚

##### 4.2.3.2 Reinforcement learning based path finding

å¼ºåŒ–å­¦ä¹ æ–¹æ³•è‡ªç„¶æ˜¯é€šè¿‡å¥–åŠ±å‡½æ•°æœºåˆ¶æ¥è¾…åŠ©KGä¸Šçš„æ¨ç†è¿‡ç¨‹ã€‚

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609145344059.png" alt="image-20220609145344059" style="zoom:50%;" />

#### 4.2.4 Improve the Graph Embeddings with Graph Neural Networks

GNNå¯ä»¥å……åˆ†èšåˆå®ä½“çš„å¤šè·³è¿æ¥å…³ç³»ã€‚

ä¸€ä¸ªé€šç”¨çš„æ€è·¯æ˜¯ï¼š

1. é€šè¿‡é¢„å…ˆå®šä¹‰çš„å­å›¾æ˜ å°„æ¥å°†è¯­å¥ä¸­çš„è¯æ±‡å¯¹åº”åˆ°KGä¸­çš„å®ä½“ä¸­ï¼š$U \times X \rightarrow U_{sub}$
2. å¯¹äºæ¯ä¸€ä¸ªä¸Šè¿°çš„$U_{sub}$,æ‰¾åˆ°ä¸€ä¸ªç”±Kè·³é‚»å±…æ„æˆçš„å­å›¾$G_{sub}$
3. å¯¹äºæ¯ä¸€ä¸ªå­å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œåšä¸€ä¸ªembedding : $u$
4. å¯¹äºæ‰€æœ‰çš„å­å›¾ä¸­çš„èŠ‚ç‚¹åšä¸€ä¸ªreadoutå¾—åˆ°ä¸€ä¸ªå­å›¾çš„embedding : $h_{subG} = READOUT(\{u^{(k)}, u \in U_{sub}\})$
5. å°†è¿™ä¸ª$h_{subG}$ä½œä¸ºembeddingèå…¥åˆ°sequenceçš„embeddingä¸­ã€‚

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609150810216.png" alt="image-20220609150810216" style="zoom:50%;" />



#### 4.2.5 KGæ€»ç»“ï¼š

* KGEæ˜¯æœ€æ—©æå‡ºçš„æœ‰å…³äºåˆ©ç”¨KGæ¥è¾…åŠ©MLGçš„æ–¹æ³•ã€‚å®ƒå­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜æ˜¯å¯¹äºGraphçš„embeddingä»¥åŠå¯¹äºseqçš„embeddingä¸¤ä¸ªè¿‡ç¨‹æ˜¯åˆ†å¼€çš„ï¼Œå› ä¸ºäºŒè€…å¯èƒ½ä¸åœ¨ä¸€ä¸ªå‘é‡ç©ºé—´ä¸Šï¼Œå¯¼è‡´èåˆçš„æ—¶å€™ä¼šå‡ºç°é—®é¢˜ã€‚

* ä¸ºäº†è§£å†³è¿™ä¸ªç©ºé—´ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œç›´æ¥åˆ©ç”¨Knowledge Triplet Informationçš„æ–¹æ³•å¹²è„†å°±æŠŠKGè½¬åŒ–æˆseqäº†ï¼Œæœ‰æ•ˆå¯¹ä¸Šè¿°é—®é¢˜è¿›è¡Œäº†è§£å†³ã€‚

ä½†æ˜¯è¿™ä¸¤ä¸ªæ–¹æ³•éƒ½æœ‰ä¸¤ä¸ªååˆ†æ˜æ˜¾çš„é—®é¢˜ï¼š

1. åªèƒ½å¤„ç†ä¸€è·³é‚»å±…å…³ç³»
2. ä¸æ”¯æŒåœ¨è¿›è¡Œä¸‹æ¸¸ä»»åŠ¡çš„æ—¶å€™è®¿é—®KGä¸­çš„ä¿¡æ¯æ¥åŸºäºæ­¤è¿›è¡Œæ¨ç†ã€‚

* åŸºäºè·¯å¾„çš„KGåˆ©ç”¨æ–¹æ³•å¯ä»¥æ”¯æŒåœ¨KGç»“æ„ä¸Šè¿›è¡Œæ¨ç†ï¼Œå¹¶ä¸”æ‹¥æœ‰å¾ˆå¥½çš„å¯è§£é‡Šæ€§ã€‚ä½†æ˜¯è¿™ç§æ–¹æ³•ä»ç„¶å­˜åœ¨é—®é¢˜ï¼šç”±äºè·¯å¾„æ•°é‡çš„é™åˆ¶ï¼ˆéšæœºæ¸¸èµ°ï¼‰ï¼Œæ— æ³•ä¿è¯å¯ä»¥æå–åˆ°å…¨éƒ¨æ•°æ®ä¸Šçš„ä¿¡æ¯ï¼›åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ€è·¯å­˜åœ¨çš„é—®é¢˜æ˜¯å¯¹äºå™ªå£°æ•°æ®ååˆ†æ•æ„Ÿã€‚
* æœ€åä¸€ç§æ˜¯åˆ©ç”¨GNNæ¥å¤„ç†KGï¼Œè¿™ç§æ–¹æ³•èƒ½å¤ŸåŒæ—¶ç»“åˆKGçš„ç»“æ„ä»¥åŠè¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶ä¸”å¯ä»¥åŒæ—¶å¯¹Graph encoderä»¥åŠ text encoderåˆ©ç”¨BPè¿›è¡Œè®­ç»ƒï¼Œç›¸æ¯”äºå…¶ä»–æ–¹æ³•ç‹¬ç«‹åœ°å¯¹å¾…KGä»¥åŠtextï¼Œåˆ©ç”¨GNNå¯ä»¥è®©Graphå’Œtextçš„ç»“åˆæ›´åŠ ç´§å¯†ã€‚

ä½†æ˜¯åä¸¤ç§æ–¹æ³•åŒæ ·å­˜åœ¨é—®é¢˜ï¼š

1. å¤æ‚ç¨‹åº¦ç›¸æ¯”äºå‰ä¸¤ç§æ–¹æ³•è¦å¤§å¾ˆå¤šã€‚

2. å¯¹äºæœ‰ç”¨ä¿¡æ¯çš„è¦†ç›–ç‡è¿˜æ˜¯ä¸å¤Ÿé«˜ã€‚

   > For example, people use ConceptNet, a widely used commonsense KG, to retrieve the subgraph on three generative commonsense reasoning tasks. The task datasets are ComVE [57], ğ›¼-NLG [7], and ROCSories [46]. We found 25.1% / 24.2% / 21.1% of concepts in the output could be found on ConceptNet, but only 11.4% / 8.1% / 5.7% of concepts in the output can be found on the retrieved 2-hop sequence-associated subgraph, respectively. It means that a large portion of relevant concepts on the KG are not utilized in the generation process.

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609160153137.png" alt="image-20220609160153137" style="zoom:50%;" />

### 4.3 by Grounded Text

ä¸Šè¿°çš„å‡ ç§æ–¹æ³•éƒ½å±€é™äºå…ˆåˆ©ç”¨äººå·¥å°†çŸ¥è¯†æ”¶é›†èµ·æ¥ç„¶åè®©æ¨¡å‹å»å­¦ä¹ ï¼Œè€Œåˆ©ç”¨grounded textçš„æ–¹æ³•çš„æ€è·¯æ˜¯å°è¯•ä»å¤–éƒ¨è‡ªä¸»è·å–knowledgeï¼Œä¾‹å¦‚ç™¾ç§‘ç½‘ã€ç¤¾äº¤å¹³å°ã€è´­ç‰©å¹³å°ç­‰ã€‚

å¦‚ä½•å¤„ç†grounded textä»¥åŠè¾“å…¥åºåˆ—å…³ç³»ï¼Œæ–¹æ³•åˆ†ä¸ºä»¥ä¸‹ä¸¤ç§ï¼š

* Guiding Generation with Retrieved Information
* modeling background knowledge into response generation

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609172349943.png" alt="image-20220609172349943" style="zoom:50%;" />

#### 4.3.1 Guiding Generation with Retrieved Information

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609163858077.png" alt="image-20220609163858077" style="zoom:50%;" />

å¸Œæœ›ä»å¤–éƒ¨æ•°æ®æºä¸­æ£€ç´¢æœ‰ç”¨çš„çŸ¥è¯†ï¼Œé¢ä¸´å¤–éƒ¨æ•°æ®å™ªå£°è¾ƒå¤šçš„é—®é¢˜ï¼Œå› æ­¤è¦è®¾è®¡ç‰¹æ®Šçš„æ•°æ®æ£€ç´¢ä»¥åŠåˆ©ç”¨æ–¹æ³•ï¼Œåˆ†ä¸ºä»¥ä¸‹ä¸¤ç§ï¼š

##### 4.3.1.1 Retrieval-augmented generation (RAG)

retrieve-then-generateï¼Œä¸€ç§äºŒé˜¶æ–¹æ³•ï¼Œå…·ä½“çš„å®æ–½åŠæ³•åŒ…æ‹¬ï¼š

1. é€šè¿‡ç»™å®šçš„æ•°æ®æ¥ä»æ•°æ®æºè¿›è¡Œmatching
2. åˆ©ç”¨ç»Ÿè®¡å­¦æ–¹æ³•ï¼ˆä¾‹å¦‚BM25ï¼‰æ¥å¯¹å¤§é‡æ•°æ®æºè¿›è¡Œæ‰“åˆ†
3. neuralçš„æ–¹æ³•ï¼ˆDPRï¼‰

##### 4.3.1.2 Retrieve, rerank and rewrite ($R^3$)

ç›®çš„æ˜¯è¦æ‰¾åˆ°èƒ½å¤Ÿrewriteå’Œeditingçš„æœ€åˆé€‚ã€æœ€æ˜ç¡®çš„æ•°æ®æºã€‚

é€šè¿‡soft templatesæ–¹æ³•ä»çŸ¥è¯†æºä¸­æå–ç›¸å…³çš„æ€»ç»“ï¼Œrerankæ‰¾åˆ°å…¶ä¸­æœ€ç¬¦åˆçš„templateï¼Œæœ€årewriteï¼šåŒæ—¶åˆ©ç”¨sourceä»¥åŠtemplateæ¥è¿›è¡Œtext generation



<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609172332414.png" alt="image-20220609172332414" style="zoom:50%;" />

#### 4.3.2 modeling background knowledge into response generation.

èƒŒæ™¯ä¿¡æ¯ç±»ä¼¼äºtopicï¼Œç›®çš„æ˜¯è®©ç”Ÿæˆçš„åºåˆ—ä¸è¦åç¦»å¤§çš„æ–¹å‘ã€‚

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609172253093.png" alt="image-20220609172253093" style="zoom:50%;" />



## 5. BENCHMARK, TOOLKIT AND LEADERBOARD PERFORMANCE

æœ¬æ–‡é€‰å–äº†9ä¸ªä»¥knowledge-enhencedä¸ºç‰¹ç‚¹çš„benchmarkæ•°æ®é›†ï¼Œ

ç­›é€‰çš„æ ‡å‡†ï¼š

1. å…¬å¼€
2. å…³æ³¨äºå¤šæ ·ä»»åŠ¡
3. åŒç±»ä»»åŠ¡æœ€å¤šé€‰3ä¸ª
4. å†…éƒ¨ã€å¤–éƒ¨æ•°æ®æºå‡æœ‰æ‰€æ”¶çº³
5. æ›´åå‘äºé‡‡ç”¨å¤šå‚è€ƒæ€§çš„æ•°æ®é›†

<img src="Knowledge-enhenced_NLG_Survey.assets/image-20220609172741007.png" alt="image-20220609172741007" style="zoom:50%;" />

æ–‡ç« å¯¹æ¯ä¸ªæ”¶å½•çš„æ•°æ®é›†è¿›è¡Œäº†è¯¦ç»†ä»‹ç»ï¼Œåœ¨æ–‡ç« åŸæ–‡ä¸­å‘ˆç°ï¼Œæ­¤å¤„ä¸åˆ—ä¸¾ã€‚

## 6. FUTURE DIRECTIONS

* Incorporate Knowledge into Visual-Language Generation Tasks

  ä¾‹å¦‚æè¿°å¯è§†åŒ–åœºæ™¯ã€å›¾ç‰‡ç›¸å…³çš„é—®ç­”ç­‰ã€‚å¯ä»¥å°†æ›´å¤šçš„å¤–éƒ¨çŸ¥è¯†èå…¥å…¶ä¸­ï¼Œåº”è¯¥ä¼šæœ‰æ¯”ç°åœ¨æ›´å¥½çš„æ•ˆæœã€‚

  å¯ä»¥å°è¯•ä»¥å›¾ç‰‡ã€æ–‡æœ¬ç­‰å¤šç§ç±»å‹çš„æ•°æ®ä½œä¸ºçŸ¥è¯†è¿›è¡Œæ£€ç´¢æ¥è¾…åŠ©è§£å†³opendomainQAç­‰

* Learning Knowledge from Broader Sources

  å¯ä»¥å°†knowledgeçš„æ¥æºä¸ä»…ä»…å±€é™äºæ–‡æœ¬ã€KGã€KBç­‰ï¼Œå¯ä»¥å°è¯•ä»å­—å…¸ã€ç½‘ç«™ã€è¡¨æ ¼ç­‰å¤šç§æºå¤´æ¥è·å–æ•°æ®ã€‚

  å¦å¤–ï¼Œä»é¢„è®­ç»ƒæ¨¡å‹ä¸­æå–knowledgeçš„æ–¹æ³•ç›®å‰è¿˜æ¯”è¾ƒå±€é™ï¼Œåœ¨story generationçš„ä»»åŠ¡ä¸Šé¢„è®­ç»ƒ + å¾®è°ƒæ–¹æ³•ä¹Ÿä¸€ç›´å¾—ä¸åˆ°å¥½çš„æ•ˆæœï¼Œå› æ­¤æ¢ç´¢ç±»ä¼¼äºçŸ¥è¯†è’¸é¦çš„ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­æå–æœ‰æ•ˆknowledgeçš„æ–¹æ³•ä¹Ÿè¢«è¿«åˆ‡çš„éœ€è¦ã€‚

* Learning Knowledge from Limited Resources

  å½“NLGä»»åŠ¡é¢ä¸´ä¸€ä¸ªæ–°çš„é¢†åŸŸçš„æ—¶å€™ï¼Œç»å¸¸ç”±äºæ ·æœ¬æ•°é‡æå°‘ä»è€Œå¯¼è‡´æ¨¡å‹æ•ˆæœä¸å¥½ï¼Œä¹Ÿå°±æ˜¯æ³›åŒ–èƒ½åŠ›ä¸å¤Ÿå¼ºã€‚ä¹Ÿå°±æ˜¯æˆ‘ä»¬éœ€è¦è®©æ¨¡å‹æ‹¥æœ‰quick domain adaptationã€‚

  ç›®å‰ä¸€ä¸ªå¾ˆçƒ­é—¨çš„æ€æƒ³å«åšmeta-learningï¼Œæ”¾åˆ°NLGä¸Šå°±æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®©æ¨¡å‹å…·æœ‰é¢†åŸŸè¯†åˆ«èƒ½åŠ›ï¼Œä»è€Œèƒ½å¤Ÿè®©æ¨¡å‹åœ¨ååˆ†æœ‰é™çš„æ•°æ®ä¸Šé€‚åº”æ–°çš„ä»»åŠ¡ï¼Œè€Œæ— éœ€é‡æ–°åœ¨æ–°çš„ä»»åŠ¡ä¸Šé‡æ–°è®­ç»ƒã€‚

* Learning Knowledge in a Continuous Way

  ç±»ä¼¼äºè®©æ¨¡å‹å…·æœ‰æŒç»­å­¦ä¹ çš„èƒ½åŠ›è¿™ä¸ªæ¦‚å¿µï¼Œäººçš„çŸ¥è¯†æ˜¯åœ¨ä¸æ—¥ä¿±å¢çš„ï¼Œä½†æ˜¯ç°åœ¨çš„æ¨¡å‹å¤§å¤šæ•°è¿˜æ˜¯ä»…ä»…åœ¨é™æ€çš„çŸ¥è¯†æºä¸­è·å–çŸ¥è¯†ã€‚ä¸€ä¸ªæœ‰æ„æ€çš„å°è¯•æ˜¯è®©å¯¹è¯æœºå™¨äººåœ¨æ—¥å¸¸å¯¹è¯ä¸­ä¸æ–­å»å­¦ä¹ ã€‚è¿™ä¸ªæ–¹å‘ä¸Šå¯ä»¥æ¢ç´¢çš„æŠ€æœ¯æœ‰KGçš„å¢é•¿ï¼ˆåŠ¨æ€KGï¼‰ç­‰ã€‚

